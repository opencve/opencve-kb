{
  "cve": "CVE-2023-29374",
  "mitre": {
    "cpes": [],
    "created": "2023-04-05T00:00:00+00:00",
    "description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {},
      "cvssV4_0": {}
    },
    "mitre_repo_path": "cves/2023/29xxx/CVE-2023-29374.json",
    "references": [
      "https://github.com/hwchase17/langchain/issues/1026",
      "https://github.com/hwchase17/langchain/issues/814",
      "https://github.com/hwchase17/langchain/pull/1119",
      "https://twitter.com/rharang/status/1641899743608463365/photo/1"
    ],
    "title": null,
    "updated": "2024-08-02T14:07:45.736000+00:00",
    "vendors": [],
    "weaknesses": []
  },
  "nvd": {
    "cpes": [
      "cpe:2.3:a:langchain:langchain:*:*:*:*:*:*:*:*"
    ],
    "created": "2023-04-05T02:15:37.340000+00:00",
    "description": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {
        "score": 9.8,
        "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"
      },
      "cvssV4_0": {}
    },
    "nvd_repo_path": "2023/CVE-2023-29374.json",
    "references": [
      "https://github.com/hwchase17/langchain/issues/1026",
      "https://github.com/hwchase17/langchain/issues/814",
      "https://github.com/hwchase17/langchain/pull/1119",
      "https://twitter.com/rharang/status/1641899743608463365/photo/1"
    ],
    "title": null,
    "updated": "2023-04-17T16:57:22.070000+00:00",
    "vendors": [
      "langchain",
      "langchain$PRODUCT$langchain"
    ],
    "weaknesses": [
      "CWE-74"
    ]
  },
  "opencve": {
    "changes": [],
    "cpes": {
      "data": [
        "cpe:2.3:a:langchain:langchain:*:*:*:*:*:*:*:*"
      ],
      "providers": [
        "nvd"
      ]
    },
    "created": {
      "data": "2023-04-05T00:00:00+00:00",
      "provider": "mitre"
    },
    "description": {
      "data": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
      "provider": "mitre"
    },
    "metrics": {
      "cvssV2_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_1": {
        "data": {
          "score": 9.8,
          "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"
        },
        "provider": "nvd"
      },
      "cvssV4_0": {
        "data": {},
        "provider": null
      },
      "kev": {
        "data": {},
        "provider": null
      },
      "ssvc": {
        "data": {},
        "provider": null
      },
      "threat_severity": {
        "data": null,
        "provider": null
      }
    },
    "references": {
      "data": [
        "https://github.com/hwchase17/langchain/issues/1026",
        "https://github.com/hwchase17/langchain/issues/814",
        "https://github.com/hwchase17/langchain/pull/1119",
        "https://twitter.com/rharang/status/1641899743608463365/photo/1"
      ],
      "providers": [
        "mitre",
        "nvd"
      ]
    },
    "title": {
      "data": null,
      "provider": null
    },
    "updated": {
      "data": "2024-08-02T14:07:45.736000+00:00",
      "provider": "mitre"
    },
    "vendors": {
      "data": [
        "langchain",
        "langchain$PRODUCT$langchain"
      ],
      "providers": [
        "nvd"
      ]
    },
    "weaknesses": {
      "data": [
        "CWE-74"
      ],
      "providers": [
        "nvd"
      ]
    }
  }
}