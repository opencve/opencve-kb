{
  "cve": "CVE-2024-27005",
  "mitre": {
    "cpes": [],
    "created": "2024-05-01T05:28:59.193000+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\n\ninterconnect: Don't access req_list while it's being manipulated\n\nThe icc_lock mutex was split into separate icc_lock and icc_bw_lock\nmutexes in [1] to avoid lockdep splats. However, this didn't adequately\nprotect access to icc_node::req_list.\n\nThe icc_set_bw() function will eventually iterate over req_list while\nonly holding icc_bw_lock, but req_list can be modified while only\nholding icc_lock. This causes races between icc_set_bw(), of_icc_get(),\nand icc_put().\n\nExample A:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     icc_put(path_b)\n                                       mutex_lock(&icc_lock);\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                       hlist_del(...\n        <r = invalid pointer>\n\nExample B:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     path_b = of_icc_get()\n                                       of_icc_get_by_index()\n                                         mutex_lock(&icc_lock);\n                                         path_find()\n                                           path_init()\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                             hlist_add_head(...\n        <r = invalid pointer>\n\nFix this by ensuring icc_bw_lock is always held before manipulating\nicc_node::req_list. The additional places icc_bw_lock is held don't\nperform any memory allocations, so we should still be safe from the\noriginal lockdep splats that motivated the separate locks.\n\n[1] commit af42269c3523 (\"interconnect: Fix locking for runpm vs reclaim\")",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {},
      "cvssV4_0": {}
    },
    "mitre_repo_path": "cves/2024/27xxx/CVE-2024-27005.json",
    "references": [
      "https://git.kernel.org/stable/c/4c65507121ea8e0b47fae6d2049c8688390d46b6",
      "https://git.kernel.org/stable/c/d0d04efa2e367921654b5106cc5c05e3757c2b42",
      "https://git.kernel.org/stable/c/de1bf25b6d771abdb52d43546cf57ad775fb68a1"
    ],
    "title": "interconnect: Don't access req_list while it's being manipulated",
    "updated": "2024-08-02T00:21:05.951000+00:00",
    "vendors": [],
    "weaknesses": []
  },
  "nvd": {
    "cpes": [],
    "created": "2024-05-01T06:15:18.883000+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\n\ninterconnect: Don't access req_list while it's being manipulated\n\nThe icc_lock mutex was split into separate icc_lock and icc_bw_lock\nmutexes in [1] to avoid lockdep splats. However, this didn't adequately\nprotect access to icc_node::req_list.\n\nThe icc_set_bw() function will eventually iterate over req_list while\nonly holding icc_bw_lock, but req_list can be modified while only\nholding icc_lock. This causes races between icc_set_bw(), of_icc_get(),\nand icc_put().\n\nExample A:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     icc_put(path_b)\n                                       mutex_lock(&icc_lock);\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                       hlist_del(...\n        <r = invalid pointer>\n\nExample B:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     path_b = of_icc_get()\n                                       of_icc_get_by_index()\n                                         mutex_lock(&icc_lock);\n                                         path_find()\n                                           path_init()\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                             hlist_add_head(...\n        <r = invalid pointer>\n\nFix this by ensuring icc_bw_lock is always held before manipulating\nicc_node::req_list. The additional places icc_bw_lock is held don't\nperform any memory allocations, so we should still be safe from the\noriginal lockdep splats that motivated the separate locks.\n\n[1] commit af42269c3523 (\"interconnect: Fix locking for runpm vs reclaim\")",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {},
      "cvssV4_0": {}
    },
    "nvd_repo_path": "2024/CVE-2024-27005.json",
    "references": [
      "https://git.kernel.org/stable/c/4c65507121ea8e0b47fae6d2049c8688390d46b6",
      "https://git.kernel.org/stable/c/d0d04efa2e367921654b5106cc5c05e3757c2b42",
      "https://git.kernel.org/stable/c/de1bf25b6d771abdb52d43546cf57ad775fb68a1"
    ],
    "title": null,
    "updated": "2024-05-13T08:15:11.680000+00:00",
    "vendors": [],
    "weaknesses": []
  },
  "opencve": {
    "changes": [],
    "cpes": {
      "data": [],
      "providers": []
    },
    "created": {
      "data": "2024-05-01T00:00:00+00:00",
      "provider": "redhat"
    },
    "description": {
      "data": "In the Linux kernel, the following vulnerability has been resolved:\n\ninterconnect: Don't access req_list while it's being manipulated\n\nThe icc_lock mutex was split into separate icc_lock and icc_bw_lock\nmutexes in [1] to avoid lockdep splats. However, this didn't adequately\nprotect access to icc_node::req_list.\n\nThe icc_set_bw() function will eventually iterate over req_list while\nonly holding icc_bw_lock, but req_list can be modified while only\nholding icc_lock. This causes races between icc_set_bw(), of_icc_get(),\nand icc_put().\n\nExample A:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     icc_put(path_b)\n                                       mutex_lock(&icc_lock);\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                       hlist_del(...\n        <r = invalid pointer>\n\nExample B:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     path_b = of_icc_get()\n                                       of_icc_get_by_index()\n                                         mutex_lock(&icc_lock);\n                                         path_find()\n                                           path_init()\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                             hlist_add_head(...\n        <r = invalid pointer>\n\nFix this by ensuring icc_bw_lock is always held before manipulating\nicc_node::req_list. The additional places icc_bw_lock is held don't\nperform any memory allocations, so we should still be safe from the\noriginal lockdep splats that motivated the separate locks.\n\n[1] commit af42269c3523 (\"interconnect: Fix locking for runpm vs reclaim\")",
      "provider": "mitre"
    },
    "metrics": {
      "cvssV2_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_1": {
        "data": {
          "score": 5.5,
          "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
        },
        "provider": "redhat"
      },
      "cvssV4_0": {
        "data": {},
        "provider": null
      },
      "kev": {
        "data": {},
        "provider": null
      },
      "ssvc": {
        "data": {},
        "provider": null
      },
      "threat_severity": {
        "data": "Moderate",
        "provider": "redhat"
      }
    },
    "references": {
      "data": [
        "https://git.kernel.org/stable/c/4c65507121ea8e0b47fae6d2049c8688390d46b6",
        "https://git.kernel.org/stable/c/d0d04efa2e367921654b5106cc5c05e3757c2b42",
        "https://git.kernel.org/stable/c/de1bf25b6d771abdb52d43546cf57ad775fb68a1",
        "https://lore.kernel.org/linux-cve-announce/2024050147-CVE-2024-27005-e630@gregkh/T",
        "https://nvd.nist.gov/vuln/detail/CVE-2024-27005",
        "https://www.cve.org/CVERecord?id=CVE-2024-27005"
      ],
      "providers": [
        "mitre",
        "nvd",
        "redhat",
        "vulnrichment"
      ]
    },
    "title": {
      "data": "interconnect: Don't access req_list while it's being manipulated",
      "provider": "mitre"
    },
    "updated": {
      "data": "2024-08-02T00:21:05.951000+00:00",
      "provider": "mitre"
    },
    "vendors": {
      "data": [],
      "providers": []
    },
    "weaknesses": {
      "data": [],
      "providers": []
    }
  },
  "redhat": {
    "cpes": [],
    "created": "2024-05-01T00:00:00+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\ninterconnect: Don't access req_list while it's being manipulated\nThe icc_lock mutex was split into separate icc_lock and icc_bw_lock\nmutexes in [1] to avoid lockdep splats. However, this didn't adequately\nprotect access to icc_node::req_list.\nThe icc_set_bw() function will eventually iterate over req_list while\nonly holding icc_bw_lock, but req_list can be modified while only\nholding icc_lock. This causes races between icc_set_bw(), of_icc_get(),\nand icc_put().\nExample A:\nCPU0                               CPU1\n----                               ----\nicc_set_bw(path_a)\nmutex_lock(&icc_bw_lock);\nicc_put(path_b)\nmutex_lock(&icc_lock);\naggregate_requests()\nhlist_for_each_entry(r, ...\nhlist_del(...\n<r = invalid pointer>\nExample B:\nCPU0                               CPU1\n----                               ----\nicc_set_bw(path_a)\nmutex_lock(&icc_bw_lock);\npath_b = of_icc_get()\nof_icc_get_by_index()\nmutex_lock(&icc_lock);\npath_find()\npath_init()\naggregate_requests()\nhlist_for_each_entry(r, ...\nhlist_add_head(...\n<r = invalid pointer>\nFix this by ensuring icc_bw_lock is always held before manipulating\nicc_node::req_list. The additional places icc_bw_lock is held don't\nperform any memory allocations, so we should still be safe from the\noriginal lockdep splats that motivated the separate locks.\n[1] commit af42269c3523 (\"interconnect: Fix locking for runpm vs reclaim\")",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {
        "score": 5.5,
        "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
      },
      "threat_severity": "Moderate"
    },
    "redhat_repo_path": "2024/CVE-2024-27005.json",
    "references": [
      "https://lore.kernel.org/linux-cve-announce/2024050147-CVE-2024-27005-e630@gregkh/T",
      "https://nvd.nist.gov/vuln/detail/CVE-2024-27005",
      "https://www.cve.org/CVERecord?id=CVE-2024-27005"
    ],
    "title": "kernel: interconnect: Don&#39;t access req_list while it&#39;s being manipulated",
    "updated": "2024-05-01T00:00:00+00:00",
    "vendors": [],
    "weaknesses": []
  },
  "vulnrichment": {
    "cpes": [],
    "created": "2024-05-01T05:28:59.193000+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\n\ninterconnect: Don't access req_list while it's being manipulated\n\nThe icc_lock mutex was split into separate icc_lock and icc_bw_lock\nmutexes in [1] to avoid lockdep splats. However, this didn't adequately\nprotect access to icc_node::req_list.\n\nThe icc_set_bw() function will eventually iterate over req_list while\nonly holding icc_bw_lock, but req_list can be modified while only\nholding icc_lock. This causes races between icc_set_bw(), of_icc_get(),\nand icc_put().\n\nExample A:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     icc_put(path_b)\n                                       mutex_lock(&icc_lock);\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                       hlist_del(...\n        <r = invalid pointer>\n\nExample B:\n\n  CPU0                               CPU1\n  ----                               ----\n  icc_set_bw(path_a)\n    mutex_lock(&icc_bw_lock);\n                                     path_b = of_icc_get()\n                                       of_icc_get_by_index()\n                                         mutex_lock(&icc_lock);\n                                         path_find()\n                                           path_init()\n    aggregate_requests()\n      hlist_for_each_entry(r, ...\n                                             hlist_add_head(...\n        <r = invalid pointer>\n\nFix this by ensuring icc_bw_lock is always held before manipulating\nicc_node::req_list. The additional places icc_bw_lock is held don't\nperform any memory allocations, so we should still be safe from the\noriginal lockdep splats that motivated the separate locks.\n\n[1] commit af42269c3523 (\"interconnect: Fix locking for runpm vs reclaim\")",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {},
      "cvssV4_0": {},
      "kev": {},
      "ssvc": {}
    },
    "references": [
      "https://git.kernel.org/stable/c/4c65507121ea8e0b47fae6d2049c8688390d46b6",
      "https://git.kernel.org/stable/c/d0d04efa2e367921654b5106cc5c05e3757c2b42",
      "https://git.kernel.org/stable/c/de1bf25b6d771abdb52d43546cf57ad775fb68a1"
    ],
    "title": "interconnect: Don't access req_list while it's being manipulated",
    "updated": "2024-08-02T00:21:05.951000+00:00",
    "vendors": [],
    "vulnrichment_repo_path": "2024/27xxx/CVE-2024-27005.json",
    "weaknesses": []
  }
}