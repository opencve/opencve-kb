{
  "cve": "CVE-2024-46797",
  "mitre": {
    "cpes": [],
    "created": "2024-09-18T07:12:51.795000+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\n\npowerpc/qspinlock: Fix deadlock in MCS queue\n\nIf an interrupt occurs in queued_spin_lock_slowpath() after we increment\nqnodesp->count and before node->lock is initialized, another CPU might\nsee stale lock values in get_tail_qnode(). If the stale lock value happens\nto match the lock on that CPU, then we write to the \"next\" pointer of\nthe wrong qnode. This causes a deadlock as the former CPU, once it becomes\nthe head of the MCS queue, will spin indefinitely until it's \"next\" pointer\nis set by its successor in the queue.\n\nRunning stress-ng on a 16 core (16EC/16VP) shared LPAR, results in\noccasional lockups similar to the following:\n\n   $ stress-ng --all 128 --vm-bytes 80% --aggressive \\\n               --maximize --oomable --verify  --syslog \\\n               --metrics  --times  --timeout 5m\n\n   watchdog: CPU 15 Hard LOCKUP\n   ......\n   NIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   Call Trace:\n    0xc000002cfffa3bf0 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    raw_spin_rq_lock_nested.part.135+0x4c/0xd0\n    sched_ttwu_pending+0x60/0x1f0\n    __flush_smp_call_function_queue+0x1dc/0x670\n    smp_ipi_demux_relaxed+0xa4/0x100\n    xive_muxed_ipi_action+0x20/0x40\n    __handle_irq_event_percpu+0x80/0x240\n    handle_irq_event_percpu+0x2c/0x80\n    handle_percpu_irq+0x84/0xd0\n    generic_handle_irq+0x54/0x80\n    __do_irq+0xac/0x210\n    __do_IRQ+0x74/0xd0\n    0x0\n    do_IRQ+0x8c/0x170\n    hardware_interrupt_common_virt+0x29c/0x2a0\n   --- interrupt: 500 at queued_spin_lock_slowpath+0x4b8/0x1490\n   ......\n   NIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   --- interrupt: 500\n    0xc0000029c1a41d00 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    futex_wake+0x100/0x260\n    do_futex+0x21c/0x2a0\n    sys_futex+0x98/0x270\n    system_call_exception+0x14c/0x2f0\n    system_call_vectored_common+0x15c/0x2ec\n\nThe following code flow illustrates how the deadlock occurs.\nFor the sake of brevity, assume that both locks (A and B) are\ncontended and we call the queued_spin_lock_slowpath() function.\n\n        CPU0                                   CPU1\n        ----                                   ----\n  spin_lock_irqsave(A)                          |\n  spin_unlock_irqrestore(A)                     |\n    spin_lock(B)                                |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++;                       |\n  (Note that nodes[0].lock == A)                |\n         |                                      |\n         ▼                                      |\n      Interrupt                                 |\n  (happens before \"nodes[0].lock = B\")          |\n         |                                      |\n         ▼                                      |\n  spin_lock_irqsave(A)                          |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++                        |\n   nodes[1].lock = A                            |\n         |                                      |\n         ▼                                      |\n  Tail of MCS queue                             |\n         |                             spin_lock_irqsave(A)\n         ▼                                      |\n  Head of MCS queue                             ▼\n         |                             CPU0 is previous tail\n         ▼                                      |\n   Spin indefinitely                            ▼\n  (until \"nodes[1].next != NULL\")      prev = get_tail_qnode(A, CPU0)\n                                                |\n                                                ▼\n                                       prev == &qnodes[CPU0].nodes[0]\n                                     (as qnodes\n---truncated---",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {},
      "cvssV4_0": {}
    },
    "mitre_repo_path": "cves/2024/46xxx/CVE-2024-46797.json",
    "references": [
      "https://git.kernel.org/stable/c/734ad0af3609464f8f93e00b6c0de1e112f44559",
      "https://git.kernel.org/stable/c/d84ab6661e8d09092de9b034b016515ef9b66085",
      "https://git.kernel.org/stable/c/f06af737e4be28c0e926dc25d5f0a111da4e2987"
    ],
    "title": "powerpc/qspinlock: Fix deadlock in MCS queue",
    "updated": "2024-09-18T07:12:51.795000+00:00",
    "vendors": [],
    "weaknesses": []
  },
  "nvd": {
    "cpes": [
      "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc1:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc2:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc3:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc4:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc5:*:*:*:*:*:*",
      "cpe:2.3:o:linux:linux_kernel:6.11:rc6:*:*:*:*:*:*"
    ],
    "created": "2024-09-18T08:15:06.403000+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\n\npowerpc/qspinlock: Fix deadlock in MCS queue\n\nIf an interrupt occurs in queued_spin_lock_slowpath() after we increment\nqnodesp->count and before node->lock is initialized, another CPU might\nsee stale lock values in get_tail_qnode(). If the stale lock value happens\nto match the lock on that CPU, then we write to the \"next\" pointer of\nthe wrong qnode. This causes a deadlock as the former CPU, once it becomes\nthe head of the MCS queue, will spin indefinitely until it's \"next\" pointer\nis set by its successor in the queue.\n\nRunning stress-ng on a 16 core (16EC/16VP) shared LPAR, results in\noccasional lockups similar to the following:\n\n   $ stress-ng --all 128 --vm-bytes 80% --aggressive \\\n               --maximize --oomable --verify  --syslog \\\n               --metrics  --times  --timeout 5m\n\n   watchdog: CPU 15 Hard LOCKUP\n   ......\n   NIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   Call Trace:\n    0xc000002cfffa3bf0 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    raw_spin_rq_lock_nested.part.135+0x4c/0xd0\n    sched_ttwu_pending+0x60/0x1f0\n    __flush_smp_call_function_queue+0x1dc/0x670\n    smp_ipi_demux_relaxed+0xa4/0x100\n    xive_muxed_ipi_action+0x20/0x40\n    __handle_irq_event_percpu+0x80/0x240\n    handle_irq_event_percpu+0x2c/0x80\n    handle_percpu_irq+0x84/0xd0\n    generic_handle_irq+0x54/0x80\n    __do_irq+0xac/0x210\n    __do_IRQ+0x74/0xd0\n    0x0\n    do_IRQ+0x8c/0x170\n    hardware_interrupt_common_virt+0x29c/0x2a0\n   --- interrupt: 500 at queued_spin_lock_slowpath+0x4b8/0x1490\n   ......\n   NIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   --- interrupt: 500\n    0xc0000029c1a41d00 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    futex_wake+0x100/0x260\n    do_futex+0x21c/0x2a0\n    sys_futex+0x98/0x270\n    system_call_exception+0x14c/0x2f0\n    system_call_vectored_common+0x15c/0x2ec\n\nThe following code flow illustrates how the deadlock occurs.\nFor the sake of brevity, assume that both locks (A and B) are\ncontended and we call the queued_spin_lock_slowpath() function.\n\n        CPU0                                   CPU1\n        ----                                   ----\n  spin_lock_irqsave(A)                          |\n  spin_unlock_irqrestore(A)                     |\n    spin_lock(B)                                |\n         |                                      |\n         ?                                      |\n   id = qnodesp->count++;                       |\n  (Note that nodes[0].lock == A)                |\n         |                                      |\n         ?                                      |\n      Interrupt                                 |\n  (happens before \"nodes[0].lock = B\")          |\n         |                                      |\n         ?                                      |\n  spin_lock_irqsave(A)                          |\n         |                                      |\n         ?                                      |\n   id = qnodesp->count++                        |\n   nodes[1].lock = A                            |\n         |                                      |\n         ?                                      |\n  Tail of MCS queue                             |\n         |                             spin_lock_irqsave(A)\n         ?                                      |\n  Head of MCS queue                             ?\n         |                             CPU0 is previous tail\n         ?                                      |\n   Spin indefinitely                            ?\n  (until \"nodes[1].next != NULL\")      prev = get_tail_qnode(A, CPU0)\n                                                |\n                                                ?\n                                       prev == &qnodes[CPU0].nodes[0]\n                                     (as qnodes\n---truncated---",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {
        "score": 5.5,
        "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
      },
      "cvssV4_0": {}
    },
    "nvd_repo_path": "2024/CVE-2024-46797.json",
    "references": [
      "https://git.kernel.org/stable/c/734ad0af3609464f8f93e00b6c0de1e112f44559",
      "https://git.kernel.org/stable/c/d84ab6661e8d09092de9b034b016515ef9b66085",
      "https://git.kernel.org/stable/c/f06af737e4be28c0e926dc25d5f0a111da4e2987"
    ],
    "title": null,
    "updated": "2024-09-20T18:18:18.093000+00:00",
    "vendors": [
      "linux",
      "linux$PRODUCT$linux_kernel"
    ],
    "weaknesses": [
      "CWE-667"
    ]
  },
  "opencve": {
    "changes": [
      {
        "created": "2024-09-18T07:30:00+00:00",
        "data": [
          {
            "details": {
              "new": "In the Linux kernel, the following vulnerability has been resolved:\n\npowerpc/qspinlock: Fix deadlock in MCS queue\n\nIf an interrupt occurs in queued_spin_lock_slowpath() after we increment\nqnodesp->count and before node->lock is initialized, another CPU might\nsee stale lock values in get_tail_qnode(). If the stale lock value happens\nto match the lock on that CPU, then we write to the \"next\" pointer of\nthe wrong qnode. This causes a deadlock as the former CPU, once it becomes\nthe head of the MCS queue, will spin indefinitely until it's \"next\" pointer\nis set by its successor in the queue.\n\nRunning stress-ng on a 16 core (16EC/16VP) shared LPAR, results in\noccasional lockups similar to the following:\n\n   $ stress-ng --all 128 --vm-bytes 80% --aggressive \\\n               --maximize --oomable --verify  --syslog \\\n               --metrics  --times  --timeout 5m\n\n   watchdog: CPU 15 Hard LOCKUP\n   ......\n   NIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   Call Trace:\n    0xc000002cfffa3bf0 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    raw_spin_rq_lock_nested.part.135+0x4c/0xd0\n    sched_ttwu_pending+0x60/0x1f0\n    __flush_smp_call_function_queue+0x1dc/0x670\n    smp_ipi_demux_relaxed+0xa4/0x100\n    xive_muxed_ipi_action+0x20/0x40\n    __handle_irq_event_percpu+0x80/0x240\n    handle_irq_event_percpu+0x2c/0x80\n    handle_percpu_irq+0x84/0xd0\n    generic_handle_irq+0x54/0x80\n    __do_irq+0xac/0x210\n    __do_IRQ+0x74/0xd0\n    0x0\n    do_IRQ+0x8c/0x170\n    hardware_interrupt_common_virt+0x29c/0x2a0\n   --- interrupt: 500 at queued_spin_lock_slowpath+0x4b8/0x1490\n   ......\n   NIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   --- interrupt: 500\n    0xc0000029c1a41d00 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    futex_wake+0x100/0x260\n    do_futex+0x21c/0x2a0\n    sys_futex+0x98/0x270\n    system_call_exception+0x14c/0x2f0\n    system_call_vectored_common+0x15c/0x2ec\n\nThe following code flow illustrates how the deadlock occurs.\nFor the sake of brevity, assume that both locks (A and B) are\ncontended and we call the queued_spin_lock_slowpath() function.\n\n        CPU0                                   CPU1\n        ----                                   ----\n  spin_lock_irqsave(A)                          |\n  spin_unlock_irqrestore(A)                     |\n    spin_lock(B)                                |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++;                       |\n  (Note that nodes[0].lock == A)                |\n         |                                      |\n         ▼                                      |\n      Interrupt                                 |\n  (happens before \"nodes[0].lock = B\")          |\n         |                                      |\n         ▼                                      |\n  spin_lock_irqsave(A)                          |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++                        |\n   nodes[1].lock = A                            |\n         |                                      |\n         ▼                                      |\n  Tail of MCS queue                             |\n         |                             spin_lock_irqsave(A)\n         ▼                                      |\n  Head of MCS queue                             ▼\n         |                             CPU0 is previous tail\n         ▼                                      |\n   Spin indefinitely                            ▼\n  (until \"nodes[1].next != NULL\")      prev = get_tail_qnode(A, CPU0)\n                                                |\n                                                ▼\n                                       prev == &qnodes[CPU0].nodes[0]\n                                     (as qnodes\n---truncated---",
              "old": null
            },
            "type": "description"
          },
          {
            "details": {
              "new": "powerpc/qspinlock: Fix deadlock in MCS queue",
              "old": null
            },
            "type": "title"
          },
          {
            "details": {
              "added": [
                "https://git.kernel.org/stable/c/734ad0af3609464f8f93e00b6c0de1e112f44559",
                "https://git.kernel.org/stable/c/d84ab6661e8d09092de9b034b016515ef9b66085",
                "https://git.kernel.org/stable/c/f06af737e4be28c0e926dc25d5f0a111da4e2987"
              ],
              "removed": []
            },
            "type": "references"
          }
        ],
        "id": "7c68484b-fb31-44c2-a208-9ffe076bd5ae"
      },
      {
        "created": "2024-09-18T16:15:00+00:00",
        "data": [
          {
            "details": {
              "added": [
                "https://lore.kernel.org/linux-cve-announce/2024091856-CVE-2024-46797-9174@gregkh/T",
                "https://nvd.nist.gov/vuln/detail/CVE-2024-46797",
                "https://www.cve.org/CVERecord?id=CVE-2024-46797"
              ],
              "removed": []
            },
            "type": "references"
          },
          {
            "details": {
              "added": {
                "cvssV3_1": {
                  "score": 5.5,
                  "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
                }
              },
              "removed": {},
              "updated": {
                "threat_severity": {
                  "new": "Moderate",
                  "old": null
                }
              }
            },
            "type": "metrics"
          }
        ],
        "id": "8fa9e5e5-d02f-43e2-8650-27d6a62cc9da"
      },
      {
        "created": "2024-09-20T18:45:00+00:00",
        "data": [
          {
            "details": [
              "linux",
              "linux$PRODUCT$linux_kernel"
            ],
            "type": "first_time"
          },
          {
            "details": {
              "added": [
                "CWE-667"
              ],
              "removed": []
            },
            "type": "weaknesses"
          },
          {
            "details": {
              "added": [
                "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc1:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc2:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc3:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc4:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc5:*:*:*:*:*:*",
                "cpe:2.3:o:linux:linux_kernel:6.11:rc6:*:*:*:*:*:*"
              ],
              "removed": []
            },
            "type": "cpes"
          },
          {
            "details": {
              "added": [
                "linux",
                "linux$PRODUCT$linux_kernel"
              ],
              "removed": []
            },
            "type": "vendors"
          }
        ],
        "id": "ab7621d7-6001-4d79-9de0-2fb661677beb"
      }
    ],
    "cpes": {
      "data": [
        "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc1:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc2:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc3:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc4:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc5:*:*:*:*:*:*",
        "cpe:2.3:o:linux:linux_kernel:6.11:rc6:*:*:*:*:*:*"
      ],
      "providers": [
        "nvd"
      ]
    },
    "created": {
      "data": "2024-09-18T00:00:00+00:00",
      "provider": "redhat"
    },
    "description": {
      "data": "In the Linux kernel, the following vulnerability has been resolved:\n\npowerpc/qspinlock: Fix deadlock in MCS queue\n\nIf an interrupt occurs in queued_spin_lock_slowpath() after we increment\nqnodesp->count and before node->lock is initialized, another CPU might\nsee stale lock values in get_tail_qnode(). If the stale lock value happens\nto match the lock on that CPU, then we write to the \"next\" pointer of\nthe wrong qnode. This causes a deadlock as the former CPU, once it becomes\nthe head of the MCS queue, will spin indefinitely until it's \"next\" pointer\nis set by its successor in the queue.\n\nRunning stress-ng on a 16 core (16EC/16VP) shared LPAR, results in\noccasional lockups similar to the following:\n\n   $ stress-ng --all 128 --vm-bytes 80% --aggressive \\\n               --maximize --oomable --verify  --syslog \\\n               --metrics  --times  --timeout 5m\n\n   watchdog: CPU 15 Hard LOCKUP\n   ......\n   NIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   Call Trace:\n    0xc000002cfffa3bf0 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    raw_spin_rq_lock_nested.part.135+0x4c/0xd0\n    sched_ttwu_pending+0x60/0x1f0\n    __flush_smp_call_function_queue+0x1dc/0x670\n    smp_ipi_demux_relaxed+0xa4/0x100\n    xive_muxed_ipi_action+0x20/0x40\n    __handle_irq_event_percpu+0x80/0x240\n    handle_irq_event_percpu+0x2c/0x80\n    handle_percpu_irq+0x84/0xd0\n    generic_handle_irq+0x54/0x80\n    __do_irq+0xac/0x210\n    __do_IRQ+0x74/0xd0\n    0x0\n    do_IRQ+0x8c/0x170\n    hardware_interrupt_common_virt+0x29c/0x2a0\n   --- interrupt: 500 at queued_spin_lock_slowpath+0x4b8/0x1490\n   ......\n   NIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490\n   LR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n   --- interrupt: 500\n    0xc0000029c1a41d00 (unreliable)\n    _raw_spin_lock+0x6c/0x90\n    futex_wake+0x100/0x260\n    do_futex+0x21c/0x2a0\n    sys_futex+0x98/0x270\n    system_call_exception+0x14c/0x2f0\n    system_call_vectored_common+0x15c/0x2ec\n\nThe following code flow illustrates how the deadlock occurs.\nFor the sake of brevity, assume that both locks (A and B) are\ncontended and we call the queued_spin_lock_slowpath() function.\n\n        CPU0                                   CPU1\n        ----                                   ----\n  spin_lock_irqsave(A)                          |\n  spin_unlock_irqrestore(A)                     |\n    spin_lock(B)                                |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++;                       |\n  (Note that nodes[0].lock == A)                |\n         |                                      |\n         ▼                                      |\n      Interrupt                                 |\n  (happens before \"nodes[0].lock = B\")          |\n         |                                      |\n         ▼                                      |\n  spin_lock_irqsave(A)                          |\n         |                                      |\n         ▼                                      |\n   id = qnodesp->count++                        |\n   nodes[1].lock = A                            |\n         |                                      |\n         ▼                                      |\n  Tail of MCS queue                             |\n         |                             spin_lock_irqsave(A)\n         ▼                                      |\n  Head of MCS queue                             ▼\n         |                             CPU0 is previous tail\n         ▼                                      |\n   Spin indefinitely                            ▼\n  (until \"nodes[1].next != NULL\")      prev = get_tail_qnode(A, CPU0)\n                                                |\n                                                ▼\n                                       prev == &qnodes[CPU0].nodes[0]\n                                     (as qnodes\n---truncated---",
      "provider": "mitre"
    },
    "metrics": {
      "cvssV2_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_0": {
        "data": {},
        "provider": null
      },
      "cvssV3_1": {
        "data": {
          "score": 5.5,
          "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
        },
        "provider": "nvd"
      },
      "cvssV4_0": {
        "data": {},
        "provider": null
      },
      "kev": {
        "data": {},
        "provider": null
      },
      "ssvc": {
        "data": {},
        "provider": null
      },
      "threat_severity": {
        "data": "Moderate",
        "provider": "redhat"
      }
    },
    "references": {
      "data": [
        "https://git.kernel.org/stable/c/734ad0af3609464f8f93e00b6c0de1e112f44559",
        "https://git.kernel.org/stable/c/d84ab6661e8d09092de9b034b016515ef9b66085",
        "https://git.kernel.org/stable/c/f06af737e4be28c0e926dc25d5f0a111da4e2987",
        "https://lore.kernel.org/linux-cve-announce/2024091856-CVE-2024-46797-9174@gregkh/T",
        "https://nvd.nist.gov/vuln/detail/CVE-2024-46797",
        "https://www.cve.org/CVERecord?id=CVE-2024-46797"
      ],
      "providers": [
        "mitre",
        "nvd",
        "redhat"
      ]
    },
    "title": {
      "data": "powerpc/qspinlock: Fix deadlock in MCS queue",
      "provider": "mitre"
    },
    "updated": {
      "data": "2024-09-20T18:18:18.093000+00:00",
      "provider": "nvd"
    },
    "vendors": {
      "data": [
        "linux",
        "linux$PRODUCT$linux_kernel"
      ],
      "providers": [
        "nvd"
      ]
    },
    "weaknesses": {
      "data": [
        "CWE-667"
      ],
      "providers": [
        "nvd"
      ]
    }
  },
  "redhat": {
    "cpes": [],
    "created": "2024-09-18T00:00:00+00:00",
    "description": "In the Linux kernel, the following vulnerability has been resolved:\npowerpc/qspinlock: Fix deadlock in MCS queue\nIf an interrupt occurs in queued_spin_lock_slowpath() after we increment\nqnodesp->count and before node->lock is initialized, another CPU might\nsee stale lock values in get_tail_qnode(). If the stale lock value happens\nto match the lock on that CPU, then we write to the \"next\" pointer of\nthe wrong qnode. This causes a deadlock as the former CPU, once it becomes\nthe head of the MCS queue, will spin indefinitely until it's \"next\" pointer\nis set by its successor in the queue.\nRunning stress-ng on a 16 core (16EC/16VP) shared LPAR, results in\noccasional lockups similar to the following:\n$ stress-ng --all 128 --vm-bytes 80% --aggressive \\\n--maximize --oomable --verify  --syslog \\\n--metrics  --times  --timeout 5m\nwatchdog: CPU 15 Hard LOCKUP\n......\nNIP [c0000000000b78f4] queued_spin_lock_slowpath+0x1184/0x1490\nLR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\nCall Trace:\n0xc000002cfffa3bf0 (unreliable)\n_raw_spin_lock+0x6c/0x90\nraw_spin_rq_lock_nested.part.135+0x4c/0xd0\nsched_ttwu_pending+0x60/0x1f0\n__flush_smp_call_function_queue+0x1dc/0x670\nsmp_ipi_demux_relaxed+0xa4/0x100\nxive_muxed_ipi_action+0x20/0x40\n__handle_irq_event_percpu+0x80/0x240\nhandle_irq_event_percpu+0x2c/0x80\nhandle_percpu_irq+0x84/0xd0\ngeneric_handle_irq+0x54/0x80\n__do_irq+0xac/0x210\n__do_IRQ+0x74/0xd0\n0x0\ndo_IRQ+0x8c/0x170\nhardware_interrupt_common_virt+0x29c/0x2a0\n--- interrupt: 500 at queued_spin_lock_slowpath+0x4b8/0x1490\n......\nNIP [c0000000000b6c28] queued_spin_lock_slowpath+0x4b8/0x1490\nLR [c000000001037c5c] _raw_spin_lock+0x6c/0x90\n--- interrupt: 500\n0xc0000029c1a41d00 (unreliable)\n_raw_spin_lock+0x6c/0x90\nfutex_wake+0x100/0x260\ndo_futex+0x21c/0x2a0\nsys_futex+0x98/0x270\nsystem_call_exception+0x14c/0x2f0\nsystem_call_vectored_common+0x15c/0x2ec\nThe following code flow illustrates how the deadlock occurs.\nFor the sake of brevity, assume that both locks (A and B) are\ncontended and we call the queued_spin_lock_slowpath() function.\nCPU0                                   CPU1\n----                                   ----\nspin_lock_irqsave(A)                          |\nspin_unlock_irqrestore(A)                     |\nspin_lock(B)                                |\n|                                      |\n▼                                      |\nid = qnodesp->count++;                       |\n(Note that nodes[0].lock == A)                |\n|                                      |\n▼                                      |\nInterrupt                                 |\n(happens before \"nodes[0].lock = B\")          |\n|                                      |\n▼                                      |\nspin_lock_irqsave(A)                          |\n|                                      |\n▼                                      |\nid = qnodesp->count++                        |\nnodes[1].lock = A                            |\n|                                      |\n▼                                      |\nTail of MCS queue                             |\n|                             spin_lock_irqsave(A)\n▼                                      |\nHead of MCS queue                             ▼\n|                             CPU0 is previous tail\n▼                                      |\nSpin indefinitely                            ▼\n(until \"nodes[1].next != NULL\")      prev = get_tail_qnode(A, CPU0)\n|\n▼\nprev == &qnodes[CPU0].nodes[0]\n(as qnodes\n---truncated---",
    "metrics": {
      "cvssV2_0": {},
      "cvssV3_0": {},
      "cvssV3_1": {
        "score": 5.5,
        "vector": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H"
      },
      "threat_severity": "Moderate"
    },
    "redhat_repo_path": "2024/CVE-2024-46797.json",
    "references": [
      "https://lore.kernel.org/linux-cve-announce/2024091856-CVE-2024-46797-9174@gregkh/T",
      "https://nvd.nist.gov/vuln/detail/CVE-2024-46797",
      "https://www.cve.org/CVERecord?id=CVE-2024-46797"
    ],
    "title": "kernel: powerpc/qspinlock: Fix deadlock in MCS queue",
    "updated": "2024-09-18T00:00:00+00:00",
    "vendors": [],
    "weaknesses": []
  }
}